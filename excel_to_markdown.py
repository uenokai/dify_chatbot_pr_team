import os
import pandas as pd
import requests
import json
import re
import argparse
from dotenv import load_dotenv

# --- ğŸ“š .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ ---
dotenv_loaded = load_dotenv()

# --- âš™ï¸ è¨­å®š ---
AZURE_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")

# LLMã®æŒ™å‹•ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
LLM_MAX_TOKENS = 2000
LLM_TEMPERATURE = 0

# --- ğŸ“‚ ãƒ‘ã‚¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®è¨­å®š (ã“ã“ã‚’ç·¨é›†ã—ã¦ãã ã•ã„) ---
DEFAULT_INPUT_FOLDER = r"C:\Users\c3005\Documents\QAå¯¾å¿œ_åŸç¨¿_dify\data_upload\01_row_file"
DEFAULT_OUTPUT_FOLDER = r"C:\Users\c3005\Documents\QAå¯¾å¿œ_åŸç¨¿_dify\data_upload\03_markdown_file"
DEFAULT_OUTPUT_FILENAME = "test.md"

# --- ğŸ¤– LLMå‘¼ã³å‡ºã—é–¢æ•° ---
def call_llm(prompt: str, expect_json: bool = True) -> str or None:
    """Azure OpenAI APIã‚’ç›´æ¥å‘¼ã³å‡ºã™æ±ç”¨é–¢æ•°"""
    if not dotenv_loaded:
        raise ValueError("`.env`ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    if not AZURE_API_KEY:
        raise ValueError("`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ `AZURE_API_KEY` ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

    url = f"{AZURE_OPENAI_ENDPOINT.rstrip('/')}/openai/deployments/{AZURE_DEPLOYMENT}/chat/completions?api-version={API_VERSION}"
    headers = {"api-key": AZURE_API_KEY, "Content-Type": "application/json"}
    
    json_data = {
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": LLM_MAX_TOKENS,
        "temperature": LLM_TEMPERATURE,
    }
    if expect_json:
        json_data["response_format"] = {"type": "json_object"}
        
    try:
        response = requests.post(url, headers=headers, json=json_data)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚{e}")
        return None
    except json.JSONDecodeError:
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: APIã‹ã‚‰ã®å¿œç­”ãŒJSONã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None

# --- ğŸ› ï¸ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def contains_japanese(text: str) -> bool:
    """æ–‡å­—åˆ—ã«æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹"""
    if not isinstance(text, str): return False
    return bool(re.search(r'[\u3040-\u3DFF\u4E00-\u9FFF]', text))

def clean_cell_for_markdown(text: str) -> str:
    """Difyã®ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ç”¨ã«ã€ã‚»ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€æ”¹è¡Œã‚’<br>ã‚¿ã‚°ã«ç½®æ›ã™ã‚‹"""
    cleaned_text = str(text).replace('\r', '').replace('|', 'ï½œ').strip()
    # \nã‚’åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã§ã¯ãªã<br>ã«ç½®æ›
    cleaned_text_with_br = cleaned_text.replace('\n', '<br>')
    # é€£ç¶šã™ã‚‹<br>ã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹ (ä¾‹: <br><br> -> <br>)
    cleaned_text_with_br = re.sub(r'(<br>\s*)+', '<br>', cleaned_text_with_br)
    return cleaned_text_with_br

# --- ğŸ§  LLMå‡¦ç† ---
def extract_qa_columns(df: pd.DataFrame, file_info: str) -> dict:
    """LLMã‚’ä½¿ã„Q&Aã‚«ãƒ©ãƒ åã‚’æŠ½å‡ºã™ã‚‹"""
    print("---- Q&Aã‚«ãƒ©ãƒ ã®æŠ½å‡ºé–‹å§‹ ----")
    df_sample_md = df.head(5).to_markdown(index=False)
    column_list = df.columns.tolist()

    prompt = f"""
    ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_info}ã€ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã‚’åˆ†æã—ã€ã€Œè³ªå•ã€ã¨ã€Œå›ç­”ã€ã«è©²å½“ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
    # åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆ
    {column_list}
    # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«
    {df_sample_md}
    # ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯
    ä¸Šè¨˜ã®ã€Œåˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆã€ã®ä¸­ã‹ã‚‰ã€ã€Œè³ªå•ã€ã«æœ€ã‚‚ãµã•ã‚ã—ã„ã‚«ãƒ©ãƒ åã‚’1ã¤é¸ã³ã€`question_column`ã®å€¤ã¨ã—ã¦ãã ã•ã„ã€‚
    åŒæ§˜ã«ã€ã€Œå›ç­”ã€ã«æœ€ã‚‚ãµã•ã‚ã—ã„ã‚«ãƒ©ãƒ åã‚’1ã¤é¸ã³ã€`answer_column`ã®å€¤ã¨ã—ã¦ãã ã•ã„ã€‚
    # çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«
    1. åˆ¤æ–­ã¯ã‚«ãƒ©ãƒ åã ã‘ã§ãªãã€ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®å†…å®¹ã‚’æœ€å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
    2. JSONã§è¿”ã™å€¤ã¯ã€ã€Œåˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆã€ã«å­˜åœ¨ã™ã‚‹æ–‡å­—åˆ—ã¨**å®Œå…¨ã«ä¸€è‡´**ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚çµ¶å¯¾ã«ãƒªã‚¹ãƒˆã«ãªã„æ–‡å­—åˆ—ã‚’ç”Ÿæˆã—ãªã„ã§ãã ã•ã„ã€‚
    3. ãŸã¨ãˆã‚«ãƒ©ãƒ åãŒã€Œè³ªå•å†…å®¹ã€ã®ã‚ˆã†ã«è¦‹ãˆã¦ã‚‚ã€ãƒªã‚¹ãƒˆã«ã‚ã‚‹ã®ãŒã€Œè³ªå•ã€ã§ã‚ã‚Œã°ã€å¿…ãšã€Œè³ªå•ã€ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
    å¿œç­”ã¯å¿…ãšã€é¸æŠã—ãŸã‚«ãƒ©ãƒ åã‚’å«ã‚€JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚
    ä¾‹: {{"question_column": "è³ªå•", "answer_column": "å›ç­”"}}
    """
    response_str = call_llm(prompt)
    try:
        return json.loads(response_str) if response_str else None
    except json.JSONDecodeError:
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ©ãƒ æŠ½å‡ºAIã®å¿œç­”ãŒä¸æ­£ãªJSONå½¢å¼ã§ã—ãŸã€‚")
        return None

def translate_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆãŒæ—¥æœ¬èªã§ãªã‘ã‚Œã°ç¿»è¨³ã™ã‚‹ã€‚æ—¥æœ¬èªãªã‚‰ãã®ã¾ã¾è¿”ã™"""
    if not text or contains_japanese(text): 
        return text
    
    # <br>ã‚¿ã‚°ã‚’ç¿»è¨³å‰ã«ä¸€æ™‚çš„ã«æ”¹è¡Œã«æˆ»ã™
    text_to_translate = text.replace('<br>', '\n')
    print(f"    - ç¿»è¨³ä¸­: \"{text_to_translate[:30]}...\"")
    prompt = f"ä»¥ä¸‹ã®è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„:\n\n{text_to_translate}"
    translated = call_llm(prompt, expect_json=False)
    
    # ç¿»è¨³å¾Œã€è¡¨ç¤ºç”¨ã«å†åº¦<br>ã‚¿ã‚°ã«å¤‰æ›
    return clean_cell_for_markdown(translated) if translated else text
# --- â–² ä¿®æ­£ç®‡æ‰€ 2 â–² ---

# --- ğŸš€ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ ---
def process_sheet(df: pd.DataFrame, file_name: str, sheet_name: str) -> pd.DataFrame or None:
    """å˜ä¸€ã®Excelã‚·ãƒ¼ãƒˆã«å¯¾ã™ã‚‹å…¨å‡¦ç†ã‚’çµ±æ‹¬ã™ã‚‹"""
    col_names = extract_qa_columns(df, f"{file_name} / {sheet_name}")
    if not col_names: return None
    
    q_col, a_col = col_names.get("question_column"), col_names.get("answer_column")
    if not all([q_col, a_col, q_col in df.columns, a_col in df.columns]):
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: AIãŒæŒ‡å®šã—ãŸã‚«ãƒ©ãƒ  '{q_col}' or '{a_col}' ãŒãƒ‡ãƒ¼ã‚¿å†…ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return None

    df = df.fillna("")
    # clean_cell_for_markdownãŒ<br>ã‚¿ã‚°ã‚’è¿”ã™ã‚ˆã†ã«ä¿®æ­£ã•ã‚ŒãŸãŸã‚ã€ã“ã“ã¯å¤‰æ›´ä¸è¦
    q_texts = df[q_col].astype(str).apply(clean_cell_for_markdown)
    a_texts = df[a_col].astype(str).apply(clean_cell_for_markdown)

    print("â†’ å¿…è¦ã«å¿œã˜ã¦è³ªå•ãƒ»å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ã‚’å®Ÿè¡Œã—ã¾ã™...")
    q_texts_translated = q_texts.apply(translate_text)
    a_texts_translated = a_texts.apply(translate_text)

    result_df = pd.DataFrame({
        "file": file_name, 
        "sheet": sheet_name, 
        "question": q_texts_translated, 
        "answer": a_texts_translated
    })
    result_df = result_df[result_df['question'].str.strip().astype(bool) & result_df['answer'].str.strip().astype(bool)]
    
    if result_df.empty:
        print("â†’ æŠ½å‡ºã§ãã‚‹æœ‰åŠ¹ãªQ&Aãƒšã‚¢ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"); return None
    
    print(f"âœ… Q&Aã‚’{len(result_df)}ä»¶æŠ½å‡ºã—ã¾ã—ãŸã€‚")
    return result_df

def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’å—ã‘å–ã‚Šã€å…¨ä½“ã®å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"""
    parser = argparse.ArgumentParser(description="æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€å†…ã®Excelã‹ã‚‰Q&Aã‚’æŠ½å‡ºã—ã€Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚")
    parser.add_argument("-i", "--input", type=str, default=DEFAULT_INPUT_FOLDER, help=f"å‡¦ç†å¯¾è±¡ã®Excelãƒ•ã‚©ãƒ«ãƒ€ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_INPUT_FOLDER}")
    parser.add_argument("-o", "--output", type=str, default=DEFAULT_OUTPUT_FOLDER, help=f"å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_OUTPUT_FOLDER}")
    parser.add_argument("-f", "--filename", type=str, default=DEFAULT_OUTPUT_FILENAME, help=f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {DEFAULT_OUTPUT_FILENAME}")
    args = parser.parse_args()

    excel_folder = args.input
    output_folder = args.output
    output_filename = args.filename
    
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
        print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {output_folder}")
        
    output_md_path = os.path.join(output_folder, output_filename)
    all_valid_dfs = []
    
    if not os.path.isdir(excel_folder):
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {excel_folder}"); return
    
    excel_files = [f for f in os.listdir(excel_folder) if f.endswith(".xlsx") and not f.startswith('~')]
    if not excel_files:
        print(f"ğŸ¤·â€â™€ï¸ ãƒ•ã‚©ãƒ«ãƒ€ã«å‡¦ç†å¯¾è±¡ã®Excelãƒ•ã‚¡ã‚¤ãƒ«(.xlsx)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"); return
        
    for file in excel_files:
        print(f"\n{'='*50}\nğŸ“‚ å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«: {file}\n{'='*50}")
        try:
            xls = pd.ExcelFile(os.path.join(excel_folder, file))
            for sheet in xls.sheet_names:
                print(f"\nğŸ“„ ã‚·ãƒ¼ãƒˆ: {sheet}")
                df = pd.read_excel(xls, sheet_name=sheet, header=0) 
                if df.empty:
                    print("â†’ ç©ºã®ã‚·ãƒ¼ãƒˆã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"); continue
                
                processed_df = process_sheet(df, file, sheet)
                if processed_df is not None and not processed_df.empty:
                    all_valid_dfs.append(processed_df)
                    print(f"ğŸ‰ ã‚·ãƒ¼ãƒˆ '{sheet}' ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã€‚")
        except Exception as e:
            print(f"ğŸš¨ é‡å¤§ãªã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{file}' ã®å‡¦ç†ä¸­ã«äºˆæœŸã›Mã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    if all_valid_dfs:
        combined_df = pd.concat(all_valid_dfs, ignore_index=True)
        
        with open(output_md_path, "w", encoding="utf-8") as f:
            for index, row in combined_df.iterrows():
                # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                question = row["question"]
                answer = row["answer"]
                file_name = row["file"]
                sheet_name = row["sheet"]

                # æŒ‡å®šã•ã‚ŒãŸå½¢å¼ã§æ›¸ãè¾¼ã‚€
                f.write(f"è³ªå•ï¼š{question}\n")
                f.write(f"å›ç­”ï¼š{answer}\n")
                f.write(f"ãƒ•ã‚¡ã‚¤ãƒ«åï¼š{file_name}\n")
                f.write(f"ã‚·ãƒ¼ãƒˆåï¼š{sheet_name}\n")
                
                # æœ€å¾Œã®è¡Œä»¥å¤–ã€å„ã‚¨ãƒ³ãƒˆãƒªã®å¾Œã«ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’æŒ¿å…¥
                if index < len(combined_df) - 1:
                    f.write("---\n")

        print(f"\n\n{'='*50}\nâœ¨ å…¨å‡¦ç†å®Œäº† âœ¨\nåˆè¨ˆ {len(combined_df)} ä»¶ã®Q&Aã‚’ {output_md_path} ã«å‡ºåŠ›ã—ã¾ã—ãŸã€‚\n{'='*50}")
    else:
        print("\n\nğŸ¤·â€â™€ï¸ æœ‰åŠ¹ãªQ&Aãƒ‡ãƒ¼ã‚¿ã‚’1ä»¶ã‚‚æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()